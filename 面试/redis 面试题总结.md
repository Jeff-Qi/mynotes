# redis 面试题总结

![img](https://pic4.zhimg.com/80/v2-d1128bb6e62db58955215c4c05ac1eab_720w.jpg)

## 数据类型

+ ### **String：**

  **String** 类型是 **Redis** 中最常使用的类型，内部的实现是通过 **SDS**（Simple Dynamic String ）来存储的。SDS 类似于 **Java** 中的 **ArrayList**，可以通过预分配冗余空间的方式来减少内存的频繁分配。

  这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。

  但是真实的开发环境中，很多仔可能会把很多比较复杂的结构也统一转成**String**去存储使用，比如有的仔他就喜欢把对象或者**List**转换为**JSONString**进行存储，拿出来再反序列话啥的。

  我在这里就不讨论这样做的对错了，但是我还是希望大家能在最合适的场景使用最合适的数据结构，对象找不到最合适的但是类型可以选最合适的嘛，之后别人接手你的代码一看这么**规范**，诶这小伙子**有点东西**呀，看到你啥都是用的**String**，**垃圾！**



  ![img](https://pic1.zhimg.com/80/v2-77d8b19253ed1b9cd43a69204272c868_720w.jpg)



  好了这些都是题外话了，道理还是希望大家记在心里，习惯成自然嘛，小习惯成就你。

  **String**的实际应用场景比较广泛的有：

  - **缓存功能：String**字符串是最常用的数据类型，不仅仅是**Redis**，各个语言都是最基本类型，因此，利用**Redis**作为缓存，配合其它数据库作为存储层，利用**Redis**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。
  - **计数器：**许多系统都会使用**Redis**作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。
  - **共享用户Session：**用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存**Cookie**，但是可以利用**Redis**将用户的**Session**集中管理，在这种模式只需要保证**Redis**的高可用，每次用户**Session**的更新和获取都可以快速完成。大大提高效率。

  ### **Hash：**

  这个是类似 **Map** 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是**这个对象没嵌套其他的对象**）给缓存在 **Redis** 里，然后每次读写缓存的时候，可以就操作 **Hash** 里的**某个字段**。

  但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。

  ### **List：**

  **List** 是有序列表，这个还是可以玩儿出很多花样的。

  比如可以通过 **List** 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。

  比如可以通过 **lrange** 命令，读取某个闭区间内的元素，可以基于 **List** 实现分页查询，这个是很棒的一个功能，基于 **Redis** 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

  比如可以搞个简单的消息队列，从 **List** 头怼进去，从 **List** 屁股那里弄出来。

  **List**本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。

  - **消息队列：Redis**的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过**Lpush**命令从左边插入数据，多个数据消费者，可以使用**BRpop**命令阻塞的“抢”列表尾部的数据。
  - 文章列表或者数据分页展示的应用。

  比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用**Redis**的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。

  ### **Set：**

  **Set** 是无序集合，会自动去重的那种。

  直接基于 **Set** 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 **JVM** 内存里的 **HashSet** 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于**Redis**进行全局的 **Set** 去重。

  可以基于 **Set** 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。

  反正这些场景比较多，因为对比很快，操作也简单，两个查询一个**Set**搞定。

  ### **Sorted Set：**

  **Sorted set** 是排序的 **Set**，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

  有序集合的使用场景与集合类似，但是set集合不是自动有序的，而**Sorted set**可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择**Sorted set**数据结构作为选择方案。

  - 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。
  - 用**Sorted Sets**来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。

  微博热搜榜，就是有个后面的热度值，前面就是名称

| 类型                 | 简介                                                   | 特性                                                         | 场景                                                         |
| -------------------- | ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String(字符串)       | 二进制安全                                             | 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M |                                                              |
| Hash(字典)           | 键值对集合,即编程语言中的Map类型                       | 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) | 存储、读取、修改用户属性                                     |
| List(列表)           | 链表(双向链表)                                         | 增删快,提供了操作某一段元素的API                             | 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列          |
| Set(集合)            | 哈希表实现,元素不重复                                  | 1,添加、删除,查找的复杂度都是O(1) 2,为集合提供了求交集、并集、差集等操作 | 1,共同好友 2,利用唯一性,统计访问网站的所有独立ip 3,好用推荐时,根据tag求交集,大于某个阈值就可以推荐 |
| Sorted Set(有序集合) | 将Set中的元素增加一个权重参数score,元素按score有序排列 | 数据插入集合时,已经进行天然排序                              | 1,排行榜 2,带权重的消息队列                                  |

## 高级用法

### **Bitmap** :

位图是支持按 bit 位来存储信息，可以用来实现 **布隆过滤器（BloomFilter）**；

### **HyperLogLog:**

供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV；

### **Geospatial:**

可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。有没有想过用Redis来实现附近的人？或者计算最优地图路径？

这三个其实也可以算作一种数据结构，不知道还有多少朋友记得，我在梦开始的地方，Redis基础中提到过，你如果只知道五种基础类型那只能拿60分，如果你能讲出高级用法，那就觉得你**有点东西**。

### **pub/sub：**

功能是订阅发布功能，可以用作简单的消息队列。

### **Pipeline：**

可以批量执行一组指令，一次性返回全部结果，可以减少频繁的请求应答。

## 事务

**Redis** 提供的不是严格的事务，**Redis** 只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去。

## 持久化

**Redis** 提供了 RDB 和 AOF 两种持久化方式，RDB 是把内存中的数据集以快照形式写入磁盘，实际操作是通过 fork 子进程执行，采用二进制压缩存储；AOF 是以文本日志的形式记录 **Redis** 处理的每一个写入或删除操作。

### RDB

1.RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。RDB是Redis默认的持久化方式，会在对应的目录下生产一个dump.rdb文件，重启会通过加载dump.rdb文件恢复数据。

2、优点

1）只有一个文件dump.rdb，方便持久化；

2） 容灾性好，一个文件可以保存到安全的磁盘；

3） 性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化（使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能) ；

4）如果数据集偏大，RDB的启动效率会比AOF更高。

3、缺点

1）数据安全性低。（RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不是特别严格的时候）

2）由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。

### AOF

1、AOF持久化是以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，文件中可以看到详细的操作记录。她的出现是为了弥补RDB的不足（数据的不一致性），所以它采用日志的形式来记录每个写操作，并追加到文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

2、优点

1）数据安全性更高，AOF持久化可以配置appendfsync属性，其中always，每进行一次命令操作就记录到AOF文件中一次。

2）通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题。

3）AOF机制的rewrite模式。(AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）)

3、缺点

1）AOF文件比RDB文件大，且恢复速度慢；数据集大的时候，比rdb启动效率低。

2）根据同步策略的不同，AOF在运行效率上往往会慢于RDB。

## 集群

master集群主要有三种模式：

### 1.主从模式

+ 特点

  + 主数据库可以进行读写操作，当读写操作导致数据变化是自动同步到从数据库
  + 从数据库只读，接受同步的数据
  + 一个master可以拥有多个slave，一个slave只属于一个master
  + slave挂了不影响其他slave的读和master的读写，重启后自动同步数据
  + master挂了，不影响slave的读，但redis不可以再写，不会重新进行master的选举

+ 工作机制

  当slave启动后，会主动向master发送sync命令。master接受到SYNC命令后再后台保存快照并缓存保存快照这段时间的命令，然后将保存的快照文件和缓存的命令发送给slave。slave接受到快照文件和命令后加载快照文件和缓存的执行命令。

+ 缺点

  若master挂了，则redis无法对外提供写服务

### 2.Sentinel模式

+ 特点

  + 建立在主从模式的基础上，如果只有一个redis，sentinel没有意义
  + master挂了以后，sentinel会再slave中选择一个作为master，并修改配置文件，修改slave指向
  + master重启后只会作为slave节点
  + 要确保sentinel的高可用性

+ 工作机制

  + 每个sentinel以每秒钟一次的频率向master/slave/sentinel发送一个ping命令，如果一个实例距离最后一次有效回复ping命令的时间超过 down-after-milliseconds 选项指定的值，则这个实例挥杯标记为主管下线
  + 如果一个master被标记为主管下线，则正在监视这个master的所有sentinel要以每秒一次的频率确认master的确进入了主观下线
  + 当有足够数量的sentinel（大于等于配置文件指定的值）在指定的时间范围内确认master的确进入了主观下线状态， 则master会被标记为客观下线
  + 在一般情况下， 每个sentinel会以每 10 秒一次的频率向它已知的所有master，slave发送 INFO 命令。当master被sentinel标记为客观下线时，sentinel向下线的master的所有slave发送 INFO 命令的频率会从 10 秒一次改为 1 秒一次
  + 若没有足够数量的sentinel同意master已经下线，master的客观下线状态就会被移除；  若master重新向sentinel的 PING 命令返回有效回复，master的主观下线状态就会被移除

+ 使用时，客户端直接连接sentinel的ip和端口即可

+ 缺点：

  当数据量过大到一台服务器存放不下的情况时，主从模式或sentinel模式就不能满足需求了

### 3.Cluster模式

cluster模式的出现就是为了解决单机Redis容量有限的问题，将Redis的数据根据一定的规则分配到多台机器。cluster可以说是sentinel和主从模式的结合体，通过cluster可以实现主从和master重选功能，所以如果配置两个副本三个分片的话，就需要六个Redis实例。因为Redis的数据是根据一定规则分配到cluster的不同机器的，当数据量过大时，可以新增机器进行扩容。

使用集群，只需要将redis配置文件中的cluster-enable配置打开即可。每个集群中至少需要三个主数据库才能正常运行，新增节点非常方便。

+ 特点
  * 多个redis节点网络互联，数据共享

  * 所有的节点都是一主一从（也可以是一主多从），其中从不提供服务，仅作为备用

  * 不支持同时处理多个key（如MSET/MGET），因为redis需要把key均匀分布在各个节点上，
    并发量很高的情况下同时创建key-value会降低性能并导致不可预测的行为

  * 支持在线增加、删除节点

  * 客户端可以连接任何一个主节点进行读写

## redis key 失效机制和淘汰策略

### 被动删除

当读/写一个已经过期的key时，会触发被动删除策略，直接删除掉这个过期key。

优点：被动删除对cpu友好，不需要消耗cpu资源

缺点：对内存不友好，失效的key仍然占用内存

### 主动删除

由于被动删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key。采用的是贪心算法。key的定期删除会在Redis的周期性执行任务默认每100ms（可以通过hz参数自定义）执行一次，针对每个db，每次循环随机选择20个key判断是否过期，如果一轮所选的key少于25%过期，则终止此次任务。如果超过25%则继续新的一轮选择，如果此次任务超过一定的时间也会被终止，避免长时间消耗cpu，造成性能损耗。

优点：主动删除对于内存友好，能够定期删除一些失效的key，释放内存空间

缺点：对于cpu不友好，需要消耗cpu资源

### 淘汰策略

如果失效的key没有被访问，也未被主动删除随机选中，那这个key就永远不会失效吗？

redis中有一个maxmemory配置，即redis最大能使用的内存，当redis的使用内存达到这个值，会根据配置的淘汰策略，对redis的key进行淘汰。

- volatile-lru：只对设置了过期时间的key进行LRU（默认值）
- allkeys-lru ： 删除lru算法的key
- volatile-random：随机删除即将过期key
- allkeys-random：随机删除
- volatile-ttl ： 删除即将过期的
- noeviction ： 永不过期，返回错误

## 缓存问题

### 1.缓存穿透

如果我们查询一个不存在的数据,则会造成一直读取数据库,如果有人恶意攻击,则会造成数据库压力过大,甚至压垮服务器,这就是所谓的缓存穿透.

解决方案：如果查询出的数据为空,也放入redis缓存,只是缓存时间设置短一些.

### 2.缓存雪崩

redis缓存放入大量key，然后某个时间点缓存集中过期失效。此刻就会造成大量的请求过来都会去同时查询数据库,而不走redis缓存,数据库压力陡增,在秒杀,双11等场景下,很容易压垮服务器.

解决方案：

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。
3. 设置热点数据永远不过期.

### 3.缓存击穿

在某些特殊节点,一个热点数据被频繁访问,在失效的瞬间就会有大量的请求进来,导致部分越过缓存去读取数据库。

解决方案：双重校验（Dubbo Check）类似线程安全的懒汉单例模式实现，保证只会有一个线程去访问数据库。
