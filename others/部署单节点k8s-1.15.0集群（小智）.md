# 部署单节点k8s-1.15.0集群

**环境信息：**

master:   192.168.33.140

node1:	192.168.33.141

node2:	192.168.33.142

## 安装docker（所有节点）： 

运行安装docker脚本，这里版本使用的是19.03.8

```bash
#!/bin/bash
echo "安装依赖工具...."
yum install -y yum-utils device-mapper-persistent-data lvm2

echo "添加阿里源"

sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo      

echo "安装并开启动Docker"

yum install -y docker-ce
systemctl start docker && systemctl enable docker

echo "添加容器加速，修改cgroup"
tee /etc/docker/daemon.json <<-'EOF'
{
 "registry-mirrors": ["https://pcy9sknd.mirror.aliyuncs.com"],
 "exec-opts": ["native.cgroupdriver=systemd"]
}
EOF

echo "查看dokcer状态"
systemctl status docker
```

## 安装kubeadm（所有节点）

- 首先添加kubernetes源

  ```bash
  cat <<EOF > /etc/yum.repos.d/kubernetes.repo
  [kubernetes]
  name=Kubernetes
  baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
  enabled=1
  gpgcheck=1
  repo_gpgcheck=1
  gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
  EOF
  ```

- 安装相应的版本（这里我安装的是1.15.0）

  ```bash
  yum install -y kubelet-1.15.0 kubeadm-1.15.0 kubectl-1.15.0
  
  systemctl start kubelet && systemctl enable kubectl
  ```

  



## 基础环境配置

- 时间同步（可选）

  ```bash
  systemctl start chronyd.service && systemctl enable chronyd.service
  ```

- 关闭防火墙和selinux

  ```bash
  systemctl stop firewalld && systemctl disable firewalld
  setenforce 0 && sed -i "s/SELINUX=enforcing$/SELINUX=disabled/g" /etc/selinux/config
  ```

- 关闭swap交换分区

  ```bash
  swapoff -a && sed -i "s/\/dev\/mapper\/centos-swap/\#\/dev\/mapper\/centos-swap/g" /etc/fstab
  ```

- 导入 IPVS 模块（用来为大量服务进行负载均衡）

  ```bash
  cat > /etc/sysconfig/modules/ipvs.modules <<EOF
  #!/bin/bash
  modprobe -- ip_vs
  modprobe -- ip_vs_rr
  modprobe -- ip_vs_wrr
  modprobe -- ip_vs_sh
  modprobe -- nf_conntrack_ipv4
  EOF
  chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4
  ```

- 开启 iptables 的 FORWARD 转发链（Docker 1.13 后禁用了 FORWARD 链，这可能会引起 Pod 间无法通信）

  ```bash
  iptables -P FORWARD ACCEPT
  sed -i '/ExecStart/a ExecStartPost=/sbin/iptables -P FORWARD ACCEPT' /usr/lib/systemd/system/docker.service
  systemctl daemon-reload
  ```

- 配置 Hosts 解析

  ```bash
  cat >> /etc/hosts << EOF
  192.168.33.140 master
  192.168.33.141 node1
  192.168.33.142 node2
  EOF
  ```

## 初始化Master节点

- 编辑kubeadm-init.yaml文件

```
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:

- groups:
  - system:bootstrappers:kubeadm:default-node-token
    token: abcdef.0123456789abcdef
    ttl: 24h0m0s
    usages:
  - signing
  - authentication
    kind: InitConfiguration
    localAPIEndpoint:
    advertiseAddress: 192.168.33.140
    bindPort: 6443
    nodeRegistration:
    criSocket: /var/run/dockershim.sock
    name: node1
    taints:
  - effect: PreferNoSchedule
    key: node-role.kubernetes.io/master

---

apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.15.0
networking:
  dnsDomain: cluster.local
  podSubnet: 10.244.0.0/16
  serviceSubnet: 10.96.0.0/12
scheduler: {}
```

**注意：**

1. advertiseAddress: 192.168.33.140	是你的master节点的ip

2. name: node1   是你的master的名字
3. podSubnet: 10.244.0.0/16   （由于这里使用的是flannel网络插件，所以使用10.244.0.0/16；如果想使用calico插件，默认网段为192.168.0.0/16）

- 执行初始化文件

  kubeadm init --config kubeadm-init.yaml

- 执行结束后，会出现一下内容

  ```bash
  [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
  [addons] Applied essential addon: CoreDNS
  [addons] Applied essential addon: kube-proxy
  
  Your Kubernetes control-plane has initialized successfully!
  
  To start using your cluster, you need to run the following as a regular user:
  
    mkdir -p $HOME/.kube
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config
  
  You should now deploy a pod network to the cluster.
  Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
    https://kubernetes.io/docs/concepts/cluster-administration/addons/
  
  Then you can join any number of worker nodes by running the following on each as root:
  
  kubeadm join 192.168.33.140:6443 --token abcdef.0123456789abcdef \
      --discovery-token-ca-cert-hash sha256:9b321d3940c84f6464ba075262e717464604439fe790bf081ec2bfc89bec82bb 
  ```

  

- 按照提示，创建文件夹并复制配合着文件到用户目录

  ```bash
  mkdir -v /root/.kube
  cp -i /etc/kubernetes/admin.conf /root/.kube/config
  scp /etc/kubernetes/admin.conf 192.168.33.141:/root/.kube/config
  scp /etc/kubernetes/admin.conf 192.168.33.142:/root/.kube/config
  ```

  注意：用户节点默认是没有.kube文件的，需要自己创建

  

  

## 初始化node节点

- 初始化node节点，加入集群

  1.在master节点运行命令：

  ```
  sudo kubeadm token create --print-join-command --ttl=0
  ```

  2.将内容复制到node节点执行：

  ```
  kubeadm join 192.168.33.140:6443 --token tdudo5.oeznovllhpnna09q     --discovery-token-ca-cert-hash sha256:9b321d3940c84f6464ba075262e717464604439fe790bf081ec2bfc89bec82bb
  ```

  

## 安装网络插件：

1. 创建flannel-k8s.yaml文件

---
```bash
- apiVersion: policy/v1beta1
  kind: PodSecurityPolicy
  metadata:
    name: psp.flannel.unprivileged
    annotations:
      seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default
      seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default
      apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
      apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
  spec:
    privileged: false
    volumes:

     - configMap
       - secret
         - emptyDir
         - hostPath
           allowedHostPaths:
           - pathPrefix: "/etc/cni/net.d"
           - pathPrefix: "/etc/kube-flannel"
           - pathPrefix: "/run/flannel"
             readOnlyRootFilesystem: false

    # Users and groups

    runAsUser:
      rule: RunAsAny
    supplementalGroups:
      rule: RunAsAny
    fsGroup:
      rule: RunAsAny

    # Privilege Escalation

    allowPrivilegeEscalation: false
    defaultAllowPrivilegeEscalation: false

    # Capabilities

    allowedCapabilities: ['NET_ADMIN']
    defaultAddCapabilities: []
    requiredDropCapabilities: []

    # Host namespaces

    hostPID: false
    hostIPC: false
    hostNetwork: true
    hostPorts:

    - min: 0
      max: 65535

    # SELinux

    seLinux:
      # SELinux is unsed in CaaSP

      rule: 'RunAsAny'
  ---

  kind: ClusterRole
  apiVersion: rbac.authorization.k8s.io/v1beta1
  metadata:
    name: flannel
  rules:

    - apiGroups: ['extensions']
      resources: ['podsecuritypolicies']
      verbs: ['use']
      resourceNames: ['psp.flannel.unprivileged']
    - apiGroups:
      - ""
        resources:
        - pods
          verbs:
        - get
    - apiGroups:
      - ""
        resources:
        - nodes
          verbs:
        - list
        - watch
    - apiGroups:
      - ""
        resources:
        - nodes/status
          verbs:
        - patch

  ---

  kind: ClusterRoleBinding
  apiVersion: rbac.authorization.k8s.io/v1beta1
  metadata:
    name: flannel
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: flannel
  subjects:

  - kind: ServiceAccount
    name: flannel
    namespace: kube-system

  ---

  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: flannel

    namespace: kube-system
  ---

  kind: ConfigMap
  apiVersion: v1
  metadata:
    name: kube-flannel-cfg
    namespace: kube-system
    labels:
      tier: node
      app: flannel
  data:
    cni-conf.json: |
      {
        "name": "cbr0",
        "plugins": [
          {
            "type": "flannel",
            "delegate": {
              "hairpinMode": true,
              "isDefaultGateway": true
            }
          },
          {
            "type": "portmap",
            "capabilities": {
              "portMappings": true
            }
          }
        ]
      }
    net-conf.json: |
      {
        "Network": "10.244.0.0/16",
        "Backend": {
          "Type": "vxlan"
        }

      }
  ---

  apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: kube-flannel-ds-amd64
    namespace: kube-system
    labels:
      tier: node
      app: flannel
  spec:
    selector:
      matchLabels:
        app: flannel
    template:
      metadata:
        labels:
          tier: node
          app: flannel
      spec:
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/arch: amd64
        tolerations:
        - operator: Exists
          effect: NoSchedule
        serviceAccountName: flannel
        initContainers:
        - name: install-cni
          image: quay.io/coreos/flannel:v0.11.0-amd64
          command:
          - cp
          args:
          - -f
          - /etc/kube-flannel/cni-conf.json
          - /etc/cni/net.d/10-flannel.conflist
          volumeMounts:
          - name: cni
            mountPath: /etc/cni/net.d
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        containers:
        - name: kube-flannel
          image: quay.io/coreos/flannel:v0.11.0-amd64
          command:
          - /opt/bin/flanneld
          resources:
            requests:
              cpu: "100m"
              memory: "50Mi"
            limits:
              cpu: "100m"
              memory: "50Mi"
          securityContext:
            privileged: false
            capabilities:
               add: ["NET_ADMIN"]
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          volumeMounts:
          - name: run
            mountPath: /run/flannel
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        volumes:
          - name: run
            hostPath:
              path: /run/flannel
          - name: cni
            hostPath:
              path: /etc/cni/net.d
          - name: flannel-cfg
            configMap:

              name: kube-flannel-cfg
  ---

  apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: kube-flannel-ds-arm64
    namespace: kube-system
    labels:
      tier: node
      app: flannel
  spec:
    selector:
      matchLabels:
        app: flannel
    template:
      metadata:
        labels:
          tier: node
          app: flannel
      spec:
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/arch: arm64
        tolerations:
        - operator: Exists
          effect: NoSchedule
        serviceAccountName: flannel
        initContainers:
        - name: install-cni
          image: quay.io/coreos/flannel:v0.11.0-arm64
          command:
          - cp
          args:
          - -f
          - /etc/kube-flannel/cni-conf.json
          - /etc/cni/net.d/10-flannel.conflist
          volumeMounts:
          - name: cni
            mountPath: /etc/cni/net.d
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        containers:
        - name: kube-flannel
          image: quay.io/coreos/flannel:v0.11.0-arm64
          command:
          - /opt/bin/flanneld
          resources:
            requests:
              cpu: "100m"
              memory: "50Mi"
            limits:
              cpu: "100m"
              memory: "50Mi"
          securityContext:
            privileged: false
            capabilities:
               add: ["NET_ADMIN"]
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          volumeMounts:
          - name: run
            mountPath: /run/flannel
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        volumes:
          - name: run
            hostPath:
              path: /run/flannel
          - name: cni
            hostPath:
              path: /etc/cni/net.d
          - name: flannel-cfg
            configMap:

              name: kube-flannel-cfg
  ---

  apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: kube-flannel-ds-arm
    namespace: kube-system
    labels:
      tier: node
      app: flannel
  spec:
    selector:
      matchLabels:
        app: flannel
    template:
      metadata:
        labels:
          tier: node
          app: flannel
      spec:
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/arch: arm
        tolerations:
        - operator: Exists
          effect: NoSchedule
        serviceAccountName: flannel
        initContainers:
        - name: install-cni
          image: quay.io/coreos/flannel:v0.11.0-arm
          command:
          - cp
          args:
          - -f
          - /etc/kube-flannel/cni-conf.json
          - /etc/cni/net.d/10-flannel.conflist
          volumeMounts:
          - name: cni
            mountPath: /etc/cni/net.d
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        containers:
        - name: kube-flannel
          image: quay.io/coreos/flannel:v0.11.0-arm
          command:
          - /opt/bin/flanneld
          resources:
            requests:
              cpu: "100m"
              memory: "50Mi"
            limits:
              cpu: "100m"
              memory: "50Mi"
          securityContext:
            privileged: false
            capabilities:
               add: ["NET_ADMIN"]
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          volumeMounts:
          - name: run
            mountPath: /run/flannel
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        volumes:
          - name: run
            hostPath:
              path: /run/flannel
          - name: cni
            hostPath:
              path: /etc/cni/net.d
          - name: flannel-cfg
            configMap:

              name: kube-flannel-cfg
  ---

  apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: kube-flannel-ds-ppc64le
    namespace: kube-system
    labels:
      tier: node
      app: flannel
  spec:
    selector:
      matchLabels:
        app: flannel
    template:
      metadata:
        labels:
          tier: node
          app: flannel
      spec:
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/arch: ppc64le
        tolerations:
        - operator: Exists
          effect: NoSchedule
        serviceAccountName: flannel
        initContainers:
        - name: install-cni
          image: quay.io/coreos/flannel:v0.11.0-ppc64le
          command:
          - cp
          args:
          - -f
          - /etc/kube-flannel/cni-conf.json
          - /etc/cni/net.d/10-flannel.conflist
          volumeMounts:
          - name: cni
            mountPath: /etc/cni/net.d
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        containers:
        - name: kube-flannel
          image: quay.io/coreos/flannel:v0.11.0-ppc64le
          command:
          - /opt/bin/flanneld
          resources:
            requests:
              cpu: "100m"
              memory: "50Mi"
            limits:
              cpu: "100m"
              memory: "50Mi"
          securityContext:
            privileged: false
            capabilities:
               add: ["NET_ADMIN"]
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          volumeMounts:
          - name: run
            mountPath: /run/flannel
          - name: flannel-cfg
            mountPath: /etc/kube-flannel/
        volumes:
          - name: run
            hostPath:
              path: /run/flannel
          - name: cni
            hostPath:
              path: /etc/cni/net.d
          - name: flannel-cfg
            configMap:

              name: kube-flannel-cfg
  ---

  apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: kube-flannel-ds-s390x
    namespace: kube-system
    labels:
      tier: node
      app: flannel
  spec:
    selector:
      matchLabels:
        app: flannel
    template:
      metadata:
        labels:
          tier: node
          app: flannel
      spec:
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/arch: s390x
        tolerations:

     - operator: Exists
       effect: NoSchedule
             serviceAccountName: flannel
             initContainers:
          - name: install-cni
            image: quay.io/coreos/flannel:v0.11.0-s390x
            command:
       - cp
         args:
       - -f
       - /etc/kube-flannel/cni-conf.json
       - /etc/cni/net.d/10-flannel.conflist
         volumeMounts:
       - name: cni
         mountPath: /etc/cni/net.d
       - name: flannel-cfg
         mountPath: /etc/kube-flannel/
             containers:
            - name: kube-flannel
              image: quay.io/coreos/flannel:v0.11.0-s390x
              command:
       - /opt/bin/flanneld
         resources:
         requests:
           cpu: "100m"
           memory: "50Mi"
         limits:
           cpu: "100m"
           memory: "50Mi"
         securityContext:
         privileged: false
         capabilities:
            add: ["NET_ADMIN"]
         env:
       - name: POD_NAME
         valueFrom:
           fieldRef:
             fieldPath: metadata.name
       - name: POD_NAMESPACE
         valueFrom:
           fieldRef:
             fieldPath: metadata.namespace
         volumeMounts:
       - name: run
         mountPath: /run/flannel
       - name: flannel-cfg
         mountPath: /etc/kube-flannel/
             volumes:
       - name: run
         hostPath:
           path: /run/flannel
       - name: cni
         hostPath:
           path: /etc/cni/net.d
       - name: flannel-cfg
         configMap:
           name: kube-flannel-cfg
```

2. 执行flannel-k8s.yaml文件

```
kubectl apply -f flannel-k8s.yaml
```

3. 等待15min，最终结果如下（状态全为running，ready）

   ```
   [root@ops-k8s-master ~]# kubectl get pod -n kube-system -o wide
   NAME                            READY   STATUS    RESTARTS   AGE    IP               NODE            NOMINATED NODE   READINESS GATES
   coredns-6967fb4995-xhrz7        1/1     Running   0          175m   10.244.0.3       node1           <none>           <none>
   coredns-6967fb4995-zw98j        1/1     Running   0          175m   10.244.0.2       node1           <none>           <none>
   etcd-node1                      1/1     Running   0          175m   192.168.33.140   node1           <none>           <none>
   kube-apiserver-node1            1/1     Running   0          175m   192.168.33.140   node1           <none>           <none>
   kube-controller-manager-node1   1/1     Running   0          174m   192.168.33.140   node1           <none>           <none>
   kube-flannel-ds-amd64-cgh2w     1/1     Running   0          166m   192.168.33.141   ops-k8s-node1   <none>           <none>
   kube-flannel-ds-amd64-dwctf     1/1     Running   0          75m    192.168.33.142   ops-k8s-node2   <none>           <none>
   kube-flannel-ds-amd64-f7vcm     1/1     Running   0          151m   192.168.33.140   node1           <none>           <none>
   kube-proxy-j4f9j                1/1     Running   0          75m    192.168.33.142   ops-k8s-node2   <none>           <none>
   kube-proxy-jmv65                1/1     Running   0          172m   192.168.33.141   ops-k8s-node1   <none>           <none>
   kube-proxy-zm4s7                1/1     Running   0          175m   192.168.33.140   node1           <none>           <none>
   kube-scheduler-node1            1/1     Running   0          175m   192.168.33.140   node1           <none>           <none>
   [root@ops-k8s-master ~]# kubectl get nodes
   NAME            STATUS   ROLES    AGE    VERSION
   node1           Ready    master   177m   v1.15.0
   ops-k8s-node1   Ready    <none>   173m   v1.15.0
   ops-k8s-node2   Ready    <none>   76m    v1.15.0
   
   
   ```

   